{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ae241a",
   "metadata": {},
   "source": [
    "# Importing Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efd26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66693a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7aaf8",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39780e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_path = \"/archive/screenplay_data/data/raw_texts/raw_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2422d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2\n",
      "From (redirected): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2&confirm=t&uuid=844d5c90-bd8d-466b-8742-334fd79bfad8\n",
      "To: c:\\Users\\syahr\\OneDrive\\Desktop\\Portfolio\\36118_NLP_Spring\\archive.zip\n",
      "100%|██████████| 689M/689M [00:46<00:00, 14.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as archive.zip\n"
     ]
    }
   ],
   "source": [
    "def extract_zip(zip_file_path, extract_to):\n",
    "    # Extract the zip file if it exists and is valid\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "            print(f\"Extracted all files to {extract_to}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {zip_file_path} does not exist.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: The file is not a valid zip file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def download_and_extract(gdrive_url, output_path, extract_to_folder, output_folder_path):\n",
    "    # Download the file\n",
    "    try:\n",
    "        gdown.download(gdrive_url, output_path, quiet=False)\n",
    "        print(f\"File downloaded and saved as {output_path}\")\n",
    "        \n",
    "        # Extract the downloaded zip file\n",
    "        extract_zip(output_path, extract_to_folder)\n",
    "\n",
    "        # Move the extracted folder and clean up\n",
    "        shutil.move(extract_to_folder, output_folder_path)\n",
    "        os.remove(output_path)\n",
    "        print(f\"Moved extracted files to {output_folder_path} and removed {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the download or extraction process: {e}\")\n",
    "\n",
    "gdrive_url = 'https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2'\n",
    "output_path = 'archive.zip'\n",
    "output_folder_path = \"archive\"\n",
    "extract_to_folder = \"c:\\\\temp_extract\"\n",
    "\n",
    "download_and_extract(gdrive_url, output_path, extract_to_folder, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a803fd",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initialize dictionary to store file names and contents\n",
    "screenplays = {}\n",
    "\n",
    "# List and iterate over all files in the folder\n",
    "for file_name in os.listdir(output_folder_path):\n",
    "    file_path = os.path.join(output_folder_path, file_name)\n",
    "    \n",
    "    # Ensure the path is an actual file before reading\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            # Read and store file content\n",
    "            with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                screenplays[file_name] = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "# Print a sample of the first ten files to check\n",
    "for i, (file_name, content) in enumerate(screenplays.items()):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"Example of {file_name}:\\n\")\n",
    "    print(content[:100])  # Print the first 100 characters as a sample\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fb253-aa84-4259-89fb-84651ca6b835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set display option for better visibility\n",
    "pd.set_option('display.max_columns', 25)\n",
    "\n",
    "# Define the path to the metadata CSV file\n",
    "csv_path = os.path.join(output_folder_path, 'movie_metadata', 'movie_meta_data.csv')\n",
    "\n",
    "# Ensure the file exists before trying to read\n",
    "if os.path.exists(csv_path):\n",
    "    # Read the CSV file\n",
    "    meta_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print the column names\n",
    "    print(meta_df.columns)\n",
    "    \n",
    "    # Display the first few rows of the dataframe\n",
    "    print(meta_df.head())\n",
    "else:\n",
    "    print(f\"File {csv_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e59b72-cb93-42e8-b01a-0b71a431dbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2ecdf5b-77f2-43c5-bd13-4dd60f6fa4c3",
   "metadata": {},
   "source": [
    "Columns relevant to us are:\n",
    "- title\n",
    "- age restrict\n",
    "- year may be of relevance in examining changes in cultural norms over time. E.g. a certain curse word might get a movie an MA rating in the 1960s but not in the 2020s. \n",
    "- budget and opening weekend may be of relevance in examining impact of classification on the movie's net.\n",
    "- imdbid may be of relevance for joining other data through the imdb database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c3354-a3b0-4619-9b7e-04b40bb18c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(screenplays.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687beb7-0c88-4c8f-a95d-c77e637bce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames are formatted as movietitle_IMDBid \n",
    "import re\n",
    "\n",
    "filenames = list(screenplays.keys())\n",
    "movie_titles = []\n",
    "ids = []\n",
    "for f in filenames:\n",
    "    # split at _ to separate title from rest of filename\n",
    "    split1 = f.split(sep=\"_\", maxsplit=1)\n",
    "    movie_title = split1[0]\n",
    "    movie_titles.append(movie_title)\n",
    "    # split at \".\" to truncate file extension\n",
    "    split2 = split1[1].split(sep=\".\", maxsplit=1)\n",
    "    id = split2[0]\n",
    "    ids.append(id)\n",
    "i = 0\n",
    "for title, id in zip(movie_titles, ids):\n",
    "    if i == 10:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Title:\", title, \" ID:\", id)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract movie titles and IDs in one step using list comprehension\n",
    "movie_titles, ids = zip(*[(f.split(\"_\", 1)[0], f.split(\"_\", 1)[1].split(\".\", 1)[0]) for f in screenplays.keys()])\n",
    "\n",
    "# Print the first 10 titles and IDs\n",
    "for i, (title, id) in enumerate(zip(movie_titles, ids)):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"Title: {title}  ID: {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970d6f3-2a58-4bd6-8790-296a0dc5502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from ids and text data\n",
    "screenplays_df = pd.DataFrame({\n",
    "    'imdbid': ids,\n",
    "    'screenplay': screenplays.values()\n",
    "})\n",
    "screenplays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4e1a6-8972-4b0b-8bf7-6cbfbf8ae07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_df.info())\n",
    "print(screenplays_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ae9c2-fc30-40b8-8331-767395ecf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with metadata on imdbid\n",
    "screenplays_df['imdbid'] = screenplays_df['imdbid'].astype(int)\n",
    "df = meta_df.merge(screenplays_df, on='imdbid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db667a-f298-4f11-8070-0ec43a2581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b878c-5525-4fef-b2f1-12cf6ea16508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lean version of the dataframe containing only columns clearly relevant to predicting age restrict classification\n",
    "relevant_cols = ['imdbid', 'title', 'year', 'opening weekend', 'budget', 'age restrict', 'genres', 'screenplay']\n",
    "df_lean = df[relevant_cols]\n",
    "df_lean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1927d-1c81-4637-a3f0-c1ff23ae4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb40e73-f7f8-4999-9dfc-7e35545f028a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lean['age restrict'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bae776fb-480d-4aa4-911f-739f14660a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the Australian age restrict classification \n",
    "def find_aus_classification(string):\n",
    "    pattern = re.compile(r', Australia:(G|PG|M|MA|MA15\\+|R), ')\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fff82-daab-4d1b-99fe-253d1bdc903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess missing values in age restrict \n",
    "df_lean['age restrict'].isnull().sum()\n",
    "print(df_lean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c62929-e946-445a-8adf-77fa2c915cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values for age restrict \n",
    "df_clean = df_lean.dropna(how='any', subset='age restrict')\n",
    "print(df_clean.shape)\n",
    "print(df_clean['age restrict'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b71e2-1530-4294-b73e-df48ccedf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_classifications = df_clean['age restrict'].apply(find_aus_classification)\n",
    "aus_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ceec1-4abd-4d7a-8b09-e0638a9facbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with aus classifications\n",
    "df_clean.loc[:,'age restrict aus'] = aus_classifications\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e65257-80fe-4ef6-81c1-0581d01bb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2625cf-e518-46e0-996a-b2c4c23c37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aus = df_clean.dropna(how='any', subset='age restrict aus')\n",
    "df_aus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a68ee962-93e8-49a0-91b6-2911154723d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save as CSVs\n",
    "# df_clean.to_csv('df_clean.csv')\n",
    "# df_aus.to_csv('df_aus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
