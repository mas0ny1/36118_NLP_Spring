{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ae241a",
   "metadata": {},
   "source": [
    "# Importing Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efd26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66693a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d28692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_1144\\2614007577.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  texts_path = \"\\archive\\screenplay_data\\data\\raw_texts\\raw_texts\"\n"
     ]
    }
   ],
   "source": [
    "# replace paths here\n",
    "root_path = os.getcwd()\n",
    "texts_path = \"\\archive\\screenplay_data\\data\\raw_texts\\raw_texts\"\n",
    "\n",
    "# Google Drive shared file URL\n",
    "gdrive_url = 'https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7aaf8",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2422d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2\n",
      "From (redirected): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2&confirm=t&uuid=9ad155a0-ef2e-4b10-85bf-7c9047cf4649\n",
      "To: c:\\Users\\syahr\\OneDrive\\Desktop\\Portfolio\\36118_NLP_Spring\\archive.zip\n",
      "100%|██████████| 689M/689M [00:44<00:00, 15.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as archive.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:archive\\\\movie_characters\\\\data\\\\movie_character_texts\\\\movie_character_texts\\\\Beavis and Butt Head Do America_0115641\\\\Ranger at Old Faithful White House Press Secretary Lieutenant at Strategic Air Command_text.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m extract_to_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc:archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mextract_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_to_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmove(extract_to_folder, folder_path)\n\u001b[0;32m     27\u001b[0m shutil\u001b[38;5;241m.\u001b[39mrmtree(extract_to_folder)\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mextract_zip\u001b[1;34m(zip_file_path, extract_to)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mzip_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted all files to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_to\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mBadZipFile:\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1744\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1741\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1801\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1797\u001b[0m         os\u001b[38;5;241m.\u001b[39mmkdir(targetpath)\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[1;32m-> 1801\u001b[0m      \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[0;32m   1802\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(source, target)\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:archive\\\\movie_characters\\\\data\\\\movie_character_texts\\\\movie_character_texts\\\\Beavis and Butt Head Do America_0115641\\\\Ranger at Old Faithful White House Press Secretary Lieutenant at Strategic Air Command_text.txt'"
     ]
    }
   ],
   "source": [
    "def extract_zip(zip_file_path, extract_to):\n",
    "    # Check if the zip file exists\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        print(f\"File {zip_file_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Extract the zip file\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "            print(f\"Extracted all files to {extract_to}\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: The file is not a valid zip file.\")\n",
    "\n",
    "output_path = 'archive.zip'\n",
    "extract_to_folder = \"c:\\\\archive\"\n",
    "folder_path = \"archive\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(gdrive_url, output_path, quiet=False)\n",
    "print(f\"File downloaded and saved as {output_path}\")\n",
    "\n",
    "extract_zip(output_path, extract_to_folder)\n",
    "shutil.move(extract_to_folder, folder_path)\n",
    "shutil.rmtree(extract_to_folder)\n",
    "os.remove(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read whole folder into a dictionary\n",
    "folder_path = f'{root_path}{texts_path}'\n",
    "screenplays = {}\n",
    "# list all files in folder and iterate over them \n",
    "for file_name in os.listdir(folder_path):\n",
    "    # get file_path by joining folder path with file_name\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # ensure path points to an actual file\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='latin-1') as f:\n",
    "            # try:\n",
    "            content = f.read()\n",
    "            screenplays[file_name] = content\n",
    "            # except:\n",
    "            #     print(f\"{file_name} could not be read.\")\n",
    "# ensure files were imported correctly by printing a sample of the first ten files \n",
    "i = 0\n",
    "for file_name, content in screenplays.items():\n",
    "    if i == 10:\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Example of {file_name}:\\n\")\n",
    "        print(content[:100])\n",
    "        print(\"-\"*50)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fb253-aa84-4259-89fb-84651ca6b835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import metadata csv\n",
    "pd.set_option('display.max_columns', 25)\n",
    "meta_df = pd.read_csv(f'{root_path}\\\\movie_metadata\\\\movie_meta_data.csv')\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e59b72-cb93-42e8-b01a-0b71a431dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecdf5b-77f2-43c5-bd13-4dd60f6fa4c3",
   "metadata": {},
   "source": [
    "Columns relevant to us are:\n",
    "- title\n",
    "- age restrict\n",
    "- year may be of relevance in examining changes in cultural norms over time. E.g. a certain curse word might get a movie an MA rating in the 1960s but not in the 2020s. \n",
    "- budget and opening weekend may be of relevance in examining impact of classification on the movie's net.\n",
    "- imdbid may be of relevance for joining other data through the imdb database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c3354-a3b0-4619-9b7e-04b40bb18c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(screenplays.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687beb7-0c88-4c8f-a95d-c77e637bce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames are formatted as movietitle_IMDBid \n",
    "import re\n",
    "\n",
    "filenames = list(screenplays.keys())\n",
    "movie_titles = []\n",
    "ids = []\n",
    "for f in filenames:\n",
    "    # split at _ to separate title from rest of filename\n",
    "    split1 = f.split(sep=\"_\", maxsplit=1)\n",
    "    movie_title = split1[0]\n",
    "    movie_titles.append(movie_title)\n",
    "    # split at \".\" to truncate file extension\n",
    "    split2 = split1[1].split(sep=\".\", maxsplit=1)\n",
    "    id = split2[0]\n",
    "    ids.append(id)\n",
    "i = 0\n",
    "for title, id in zip(movie_titles, ids):\n",
    "    if i == 10:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Title:\", title, \" ID:\", id)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970d6f3-2a58-4bd6-8790-296a0dc5502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from ids and text data\n",
    "screenplays_df = pd.DataFrame({\n",
    "    'imdbid': ids,\n",
    "    'screenplay': screenplays.values()\n",
    "})\n",
    "screenplays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4e1a6-8972-4b0b-8bf7-6cbfbf8ae07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_df.info())\n",
    "print(screenplays_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ae9c2-fc30-40b8-8331-767395ecf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with metadata on imdbid\n",
    "screenplays_df['imdbid'] = screenplays_df['imdbid'].astype(int)\n",
    "df = meta_df.merge(screenplays_df, on='imdbid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db667a-f298-4f11-8070-0ec43a2581fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b878c-5525-4fef-b2f1-12cf6ea16508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lean version of the dataframe containing only columns clearly relevant to predicting age restrict classification\n",
    "relevant_cols = ['imdbid', 'title', 'year', 'opening weekend', 'budget', 'age restrict', 'genres', 'screenplay']\n",
    "df_lean = df[relevant_cols]\n",
    "df_lean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1927d-1c81-4637-a3f0-c1ff23ae4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb40e73-f7f8-4999-9dfc-7e35545f028a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lean['age restrict'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bae776fb-480d-4aa4-911f-739f14660a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the Australian age restrict classification \n",
    "def find_aus_classification(string):\n",
    "    pattern = re.compile(r', Australia:(G|PG|M|MA|MA15\\+|R), ')\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fff82-daab-4d1b-99fe-253d1bdc903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess missing values in age restrict \n",
    "df_lean['age restrict'].isnull().sum()\n",
    "print(df_lean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c62929-e946-445a-8adf-77fa2c915cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values for age restrict \n",
    "df_clean = df_lean.dropna(how='any', subset='age restrict')\n",
    "print(df_clean.shape)\n",
    "print(df_clean['age restrict'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b71e2-1530-4294-b73e-df48ccedf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_classifications = df_clean['age restrict'].apply(find_aus_classification)\n",
    "aus_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ceec1-4abd-4d7a-8b09-e0638a9facbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with aus classifications\n",
    "df_clean.loc[:,'age restrict aus'] = aus_classifications\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e65257-80fe-4ef6-81c1-0581d01bb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2625cf-e518-46e0-996a-b2c4c23c37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aus = df_clean.dropna(how='any', subset='age restrict aus')\n",
    "df_aus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a68ee962-93e8-49a0-91b6-2911154723d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save as CSVs\n",
    "# df_clean.to_csv('df_clean.csv')\n",
    "# df_aus.to_csv('df_aus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
