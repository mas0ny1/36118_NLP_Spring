{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ae241a",
   "metadata": {},
   "source": [
    "# Importing Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efd26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\syahr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66693a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195f5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdrive_url = 'https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2'\n",
    "output_path = 'archive.zip'\n",
    "output_folder_path = \"archive\"\n",
    "extract_to_folder = \"c:\\\\temp_extract\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7aaf8",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2422d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2\n",
      "From (redirected): https://drive.google.com/uc?id=1jmSta-CD03w341lOzNjT_1qAeNDt2zL2&confirm=t&uuid=e1dea3b9-cdcd-4dd0-94db-45bd4737d81c\n",
      "To: c:\\Users\\syahr\\OneDrive\\Desktop\\Portfolio\\36118_NLP_Spring\\archive.zip\n",
      "100%|██████████| 689M/689M [01:58<00:00, 5.83MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as archive.zip\n",
      "Extracted all files to c:\\temp_extract\n",
      "Moved extracted files to archive and removed archive.zip\n"
     ]
    }
   ],
   "source": [
    "def extract_zip(zip_file_path, extract_to):\n",
    "    # Extract the zip file if it exists and is valid\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "            print(f\"Extracted all files to {extract_to}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {zip_file_path} does not exist.\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: The file is not a valid zip file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def download_and_extract(gdrive_url, output_path, extract_to_folder, output_folder_path):\n",
    "    # Download the file\n",
    "    try:\n",
    "        gdown.download(gdrive_url, output_path, quiet=False)\n",
    "        print(f\"File downloaded and saved as {output_path}\")\n",
    "        \n",
    "        # Extract the downloaded zip file\n",
    "        extract_zip(output_path, extract_to_folder)\n",
    "\n",
    "        # Move the extracted folder and clean up\n",
    "        shutil.move(extract_to_folder, output_folder_path)\n",
    "        os.remove(output_path)\n",
    "        print(f\"Moved extracted files to {output_folder_path} and removed {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the download or extraction process: {e}\")\n",
    "\n",
    "download_and_extract(gdrive_url, output_path, extract_to_folder, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a803fd",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c9dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of 10 Cloverfield Lane_1179933.txt:\n",
      "\n",
      "The Cellar\n",
      "\n",
      "by\n",
      "Josh Campbell & Matt Stuecken\n",
      "\fDARKNESS\n",
      "\n",
      "And then --\n",
      "\n",
      "A GUNNED ENGINE --\n",
      "\n",
      "BLURRED HEA\n",
      "--------------------------------------------------\n",
      "Example of 10 Things I Hate About You_0147800.txt:\n",
      "\n",
      "\n",
      "                               TEN THINGS I HATE ABOUT YOU\n",
      "          \n",
      "                written by Ka\n",
      "--------------------------------------------------\n",
      "Example of 101 Days of 101 Dalmatians_0249328.txt:\n",
      "\n",
      "107\n",
      "\f#2\n",
      "40] _DALMATIANS MARCH 17, 1995\n",
      "\n",
      "EXT. SKY. FULL MOON\n",
      "\n",
      "A huge, yellow moon. CAMERA TILTS DOWN \n",
      "--------------------------------------------------\n",
      "Example of 12 Angry Men_0118528.txt:\n",
      "\n",
      "PLEASE COPY AND RETURN |\n",
      "\n",
      "âââ_ââââ_\n",
      "\n",
      " \n",
      "\n",
      "TWELVE ANGRY MEN\n",
      "\n",
      "by Reginald Rose\n",
      "\n",
      "THE WRITIN\n",
      "--------------------------------------------------\n",
      "Example of 12 Monkeys_0114746.txt:\n",
      "\n",
      "\n",
      "\t\t\t\tTWELVE MONKEYS\n",
      "\t    \n",
      "\t\t          An original screenplay by\n",
      "\n",
      "\t\t\t\tDavid Peoples\n",
      "  \t\t\t\t     &amp;\n",
      "\n",
      "--------------------------------------------------\n",
      "Example of 12 Years a Slave_2024544.txt:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                             12 YEARS A SLAVE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                               Written \n",
      "--------------------------------------------------\n",
      "Example of 127 Hours_1542344.txt:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "                                   127 HOURS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                   Writte\n",
      "--------------------------------------------------\n",
      "Example of 13 13 13_2991516.txt:\n",
      "\n",
      "13/13/13\n",
      "\n",
      "Written by\n",
      "\n",
      "James Cullen Bressack\n",
      "\n",
      "5/15/13\n",
      "\fTEASER\n",
      "\n",
      "FADE IN:\n",
      "\n",
      "WIDE-EXT. JACKâS HOUSE-AFT\n",
      "--------------------------------------------------\n",
      "Example of 1408_0450385.txt:\n",
      "\n",
      "1408\n",
      "\n",
      "Written by\n",
      "Scott Alexander & Larry Karaszewski\n",
      "\f* FADE IN:\n",
      "\n",
      "EXT. HIGHWAY -~ DAY\n",
      "A dull highway\n",
      "--------------------------------------------------\n",
      "Example of 1492 Conquest of Paradise_0103594.txt:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                1492: CONQUEST OF PARADISE\n",
      "\n",
      "\n",
      "                             by\n",
      "\n",
      "                  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the correct path for the screenplay data\n",
    "texts_path = os.path.join(output_folder_path, \"screenplay_data\", \"data\", \"raw_texts\", \"raw_texts\")\n",
    "\n",
    "# Initialize dictionary to store file names and contents\n",
    "screenplays = {}\n",
    "\n",
    "# List and iterate over all files in the folder\n",
    "for file_name in os.listdir(texts_path):\n",
    "    file_path = os.path.join(texts_path, file_name)\n",
    "    \n",
    "    # Ensure the path is an actual file before reading\n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        try:\n",
    "            # Read and store file content\n",
    "            with open(file_path, 'r', encoding='latin-1') as f:\n",
    "                screenplays[file_name] = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "# Print a sample of the first ten files to check\n",
    "for i, (file_name, content) in enumerate(screenplays.items()):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"Example of {file_name}:\\n\")\n",
    "    print(content[:100])  # Print the first 100 characters as a sample\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8fb253-aa84-4259-89fb-84651ca6b835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['imdbid', 'title', 'akas', 'year', 'metascore', 'imdb user rating',\n",
      "       'number of imdb user votes', 'awards', 'opening weekend', 'producers',\n",
      "       'budget', 'script department', 'production companies', 'writers',\n",
      "       'directors', 'casting directors', 'cast', 'countries', 'age restrict',\n",
      "       'plot', 'plot outline', 'keywords', 'genres', 'taglines', 'synopsis'],\n",
      "      dtype='object')\n",
      "   imdbid                   title  \\\n",
      "0  120770  A Night at the Roxbury   \n",
      "1  132512          At First Sight   \n",
      "2  118661            The Avengers   \n",
      "3  215545              Bamboozled   \n",
      "4  118715        The Big Lebowski   \n",
      "\n",
      "                                                akas  year  metascore  \\\n",
      "0  Une nuit au Roxbury (France), Movida en el Rox...  1998         26   \n",
      "1  Sight Unseen (United States), Premier regard (...  1999         40   \n",
      "2  Chapeau melon et bottes de cuir (France), Mit ...  1998         12   \n",
      "3  The Very Black Show (France), It's Showtime (G...  2000         54   \n",
      "4  El gran Lebowski (Spain), O Grande Lebowski (P...  1998         71   \n",
      "\n",
      "   imdb user rating  number of imdb user votes  \\\n",
      "0                 6                      56537   \n",
      "1                 6                      12922   \n",
      "2                 3                      40784   \n",
      "3                 6                      10373   \n",
      "4                 8                     724388   \n",
      "\n",
      "                                              awards  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2  FMCJ Award 1998, Golden Reel Award 1999, Razzi...   \n",
      "3  Golden Berlin Bear 2001, Black Reel 2001, Imag...   \n",
      "4  Honorable Mention 1998, ACCA 1998, Golden Berl...   \n",
      "\n",
      "                           opening weekend  \\\n",
      "0                          United States:    \n",
      "1                          United States:    \n",
      "2  United States: $10,305,957, 16 Aug 1998   \n",
      "3                          United States:    \n",
      "4   United States: $5,533,844, 08 Mar 1998   \n",
      "\n",
      "                                           producers                   budget  \\\n",
      "0  Marie Cantin, Erin Fraser, Amy Heckerling, Ste...  $17,000,000 (estimated)   \n",
      "1           Rob Cowan, Roger Paradiso, Irwin Winkler  $60,000,000 (estimated)   \n",
      "2                       Susan Ekins, Jerry Weintraub  $60,000,000 (estimated)   \n",
      "3          Jon Kilik, Spike Lee, Kisha Imani Cameron  $10,000,000 (estimated)   \n",
      "4  Tim Bevan, John Cameron, Ethan Coen, Eric Fell...  $15,000,000 (estimated)   \n",
      "\n",
      "                      script department  \\\n",
      "0                                   NaN   \n",
      "1                                   NaN   \n",
      "2         Sharon Mansfield, Anna Worley   \n",
      "3  Shari L. Carpenter, Carolyn De Sousa   \n",
      "4                         T. Kukovinski   \n",
      "\n",
      "                                production companies  \\\n",
      "0  Broadway Pictures, Paramount Pictures, SNL Stu...   \n",
      "1                                Metro-Goldwyn-Mayer   \n",
      "2          Warner Bros., Jerry Weintraub Productions   \n",
      "3       New Line Cinema, 40 Acres & A Mule Filmworks   \n",
      "4  Polygram Filmed Entertainment, Working Title F...   \n",
      "\n",
      "                                   writers              directors  \\\n",
      "0  Steve Koren, Will Ferrell, Chris Kattan       John Fortenberry   \n",
      "1               Oliver Sacks, Steve Levitt          Irwin Winkler   \n",
      "2            Sydney Newman, Don MacPherson    Jeremiah S. Chechik   \n",
      "3                                Spike Lee              Spike Lee   \n",
      "4                    Ethan Coen, Joel Coen  Joel Coen, Ethan Coen   \n",
      "\n",
      "                            casting directors  \\\n",
      "0                              Jeff Greenberg   \n",
      "1  Kerry Barden, Billy Hopkins, Suzanne Smith   \n",
      "2                                Susie Figgis   \n",
      "3                                 Aisha Coley   \n",
      "4                               John S. Lyons   \n",
      "\n",
      "                                                cast  \\\n",
      "0  Will Ferrell, Chris Kattan, Raquel Gardner, Vi...   \n",
      "1  Val Kilmer, Mira Sorvino, Kelly McGillis, Stev...   \n",
      "2  Ralph Fiennes, Uma Thurman, Sean Connery, Patr...   \n",
      "3  Damon Wayans, Savion Glover, Jada Pinkett Smit...   \n",
      "4  Jeff Bridges, John Goodman, Julianne Moore, St...   \n",
      "\n",
      "                       countries  \\\n",
      "0                  United States   \n",
      "1                  United States   \n",
      "2                  United States   \n",
      "3                  United States   \n",
      "4  United States, United Kingdom   \n",
      "\n",
      "                                        age restrict  \\\n",
      "0  Argentina:13, Australia:M, Brazil:14, Canada:P...   \n",
      "1  Argentina:13, Australia:M, Canada:PG::(Alberta...   \n",
      "2  Argentina:13, Australia:PG, Brazil:10, Canada:...   \n",
      "3  Australia:MA, Finland:K-15, France:Tous public...   \n",
      "4  Argentina:16, Argentina:18::(cable rating), Au...   \n",
      "\n",
      "                                                plot  \\\n",
      "0  Two dim-witted brothers dream of owning their ...   \n",
      "1  A blind man has an operation to regain his sig...   \n",
      "2  Two British Agents team up to stop Sir August ...   \n",
      "3  A frustrated African-American TV writer propos...   \n",
      "4  Jeff \"The Dude\" Lebowski, mistaken for a milli...   \n",
      "\n",
      "                                        plot outline  \\\n",
      "0  The Roxbury Guys, Steve and Doug Butabi, want ...   \n",
      "1  First Sight is true to the title from start to...   \n",
      "2  British Ministry Agent John Steed, under direc...   \n",
      "3  Dark, biting satire of the television industry...   \n",
      "4  When \"the dude\" Lebowski is mistaken for a mil...   \n",
      "\n",
      "                                            keywords  \\\n",
      "0  woman-on-top, nightclub, car-accident, 1990s, ...   \n",
      "1  visual-agnosia, brother-sister-relationship, r...   \n",
      "2  good-versus-evil, heroine, evil-man, villain, ...   \n",
      "3  television-industry, african-american, referen...   \n",
      "4  rug, nihilism, pornographer, bowling-alley, de...   \n",
      "\n",
      "                                genres  \\\n",
      "0               Comedy, Music, Romance   \n",
      "1                       Drama, Romance   \n",
      "2  Action, Adventure, Sci-Fi, Thriller   \n",
      "3                 Comedy, Drama, Music   \n",
      "4                 Comedy, Crime, Sport   \n",
      "\n",
      "                                            taglines  \\\n",
      "0                                             Score!   \n",
      "1  Only Love Can Bring You To Your Senses., Scien...   \n",
      "2  Mrs. Peel, we're needed., Extraordinary crimes...   \n",
      "3                   Starring the great negroe actors   \n",
      "4  Hay quienes tratan de ganarse la vida sin move...   \n",
      "\n",
      "                                            synopsis  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3  In a New York City residence, Pierre Delacroix...  \n",
      "4  A tumbleweed rolls up a hillside just outside ...  \n"
     ]
    }
   ],
   "source": [
    "# Set display option for better visibility\n",
    "pd.set_option('display.max_columns', 25)\n",
    "\n",
    "# Define the path to the metadata CSV file\n",
    "csv_path = os.path.join(output_folder_path, 'movie_metadata', 'movie_meta_data.csv')\n",
    "\n",
    "# Ensure the file exists before trying to read\n",
    "if os.path.exists(csv_path):\n",
    "    # Read the CSV file\n",
    "    meta_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Print the column names\n",
    "    print(meta_df.columns)\n",
    "    \n",
    "    # Display the first few rows of the dataframe\n",
    "    print(meta_df.head())\n",
    "else:\n",
    "    print(f\"File {csv_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecdf5b-77f2-43c5-bd13-4dd60f6fa4c3",
   "metadata": {},
   "source": [
    "The columns of interest include:\n",
    "\n",
    "- Title\n",
    "- Age restriction\n",
    "- Year: This could be useful for analyzing shifts in cultural norms over time. For instance, certain curse words may have led to an MA rating in the 1960s but not in the 2020s.\n",
    "- Budget and Opening weekend: These may be important for studying the effect of movie classification on its financial performance.\n",
    "- IMDb ID: This might be relevant for linking additional data from the IMDb database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e94c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: 10 Cloverfield Lane  ID: 1179933\n",
      "Title: 10 Things I Hate About You  ID: 0147800\n",
      "Title: 101 Days of 101 Dalmatians  ID: 0249328\n",
      "Title: 12 Angry Men  ID: 0118528\n",
      "Title: 12 Monkeys  ID: 0114746\n",
      "Title: 12 Years a Slave  ID: 2024544\n",
      "Title: 127 Hours  ID: 1542344\n",
      "Title: 13 13 13  ID: 2991516\n",
      "Title: 1408  ID: 0450385\n",
      "Title: 1492 Conquest of Paradise  ID: 0103594\n"
     ]
    }
   ],
   "source": [
    "# Extract movie titles and IDs in one step using list comprehension\n",
    "movie_titles, ids = zip(*[(f.split(\"_\", 1)[0], f.split(\"_\", 1)[1].split(\".\", 1)[0]) for f in screenplays.keys()])\n",
    "\n",
    "# Print the first 10 titles and IDs\n",
    "for i, (title, id) in enumerate(zip(movie_titles, ids)):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f\"Title: {title}  ID: {id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f191f",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8970d6f3-2a58-4bd6-8790-296a0dc5502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>screenplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179933</td>\n",
       "      <td>The Cellar\\n\\nby\\nJosh Campbell &amp; Matt Stuecke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0147800</td>\n",
       "      <td>\\n                               TEN THINGS I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0249328</td>\n",
       "      <td>107\\n\f#2\\n40] _DALMATIANS MARCH 17, 1995\\n\\nEX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0118528</td>\n",
       "      <td>PLEASE COPY AND RETURN |\\n\\nâââ_âââ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0114746</td>\n",
       "      <td>\\n\\t\\t\\t\\tTWELVE MONKEYS\\n\\t    \\n\\t\\t        ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    imdbid                                         screenplay\n",
       "0  1179933  The Cellar\\n\\nby\\nJosh Campbell & Matt Stuecke...\n",
       "1  0147800  \\n                               TEN THINGS I ...\n",
       "2  0249328  107\\n\n",
       "#2\\n40] _DALMATIANS MARCH 17, 1995\\n\\nEX...\n",
       "3  0118528  PLEASE COPY AND RETURN |\\n\\nâââ_âââ...\n",
       "4  0114746  \\n\\t\\t\\t\\tTWELVE MONKEYS\\n\\t    \\n\\t\\t        ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame directly from screenplays, extracting ids from the keys\n",
    "screenplays_df = pd.DataFrame({\n",
    "    'imdbid': [os.path.splitext(f.split(\"_\", 1)[1])[0].replace(\".txt\", \"\") for f in screenplays.keys()],\n",
    "    'screenplay': screenplays.values()\n",
    "})\n",
    "\n",
    "screenplays_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b4e1a6-8972-4b0b-8bf7-6cbfbf8ae07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2858 entries, 0 to 2857\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   imdbid                     2858 non-null   int64 \n",
      " 1   title                      2858 non-null   object\n",
      " 2   akas                       2652 non-null   object\n",
      " 3   year                       2858 non-null   int64 \n",
      " 4   metascore                  2858 non-null   int64 \n",
      " 5   imdb user rating           2858 non-null   int64 \n",
      " 6   number of imdb user votes  2858 non-null   int64 \n",
      " 7   awards                     2243 non-null   object\n",
      " 8   opening weekend            1739 non-null   object\n",
      " 9   producers                  2640 non-null   object\n",
      " 10  budget                     1624 non-null   object\n",
      " 11  script department          2220 non-null   object\n",
      " 12  production companies       2682 non-null   object\n",
      " 13  writers                    2696 non-null   object\n",
      " 14  directors                  2658 non-null   object\n",
      " 15  casting directors          2141 non-null   object\n",
      " 16  cast                       2806 non-null   object\n",
      " 17  countries                  2678 non-null   object\n",
      " 18  age restrict               2526 non-null   object\n",
      " 19  plot                       2709 non-null   object\n",
      " 20  plot outline               2457 non-null   object\n",
      " 21  keywords                   2601 non-null   object\n",
      " 22  genres                     2846 non-null   object\n",
      " 23  taglines                   2256 non-null   object\n",
      " 24  synopsis                   1852 non-null   object\n",
      "dtypes: int64(5), object(20)\n",
      "memory usage: 558.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2858 entries, 0 to 2857\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   imdbid      2858 non-null   object\n",
      " 1   screenplay  2858 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(meta_df.info())\n",
    "print(screenplays_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "996ae9c2-fc30-40b8-8331-767395ecf0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>title</th>\n",
       "      <th>akas</th>\n",
       "      <th>year</th>\n",
       "      <th>metascore</th>\n",
       "      <th>imdb user rating</th>\n",
       "      <th>number of imdb user votes</th>\n",
       "      <th>awards</th>\n",
       "      <th>opening weekend</th>\n",
       "      <th>producers</th>\n",
       "      <th>budget</th>\n",
       "      <th>script department</th>\n",
       "      <th>...</th>\n",
       "      <th>directors</th>\n",
       "      <th>casting directors</th>\n",
       "      <th>cast</th>\n",
       "      <th>countries</th>\n",
       "      <th>age restrict</th>\n",
       "      <th>plot</th>\n",
       "      <th>plot outline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "      <th>taglines</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>screenplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120770</td>\n",
       "      <td>A Night at the Roxbury</td>\n",
       "      <td>Une nuit au Roxbury (France), Movida en el Rox...</td>\n",
       "      <td>1998</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>56537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States:</td>\n",
       "      <td>Marie Cantin, Erin Fraser, Amy Heckerling, Ste...</td>\n",
       "      <td>$17,000,000 (estimated)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>John Fortenberry</td>\n",
       "      <td>Jeff Greenberg</td>\n",
       "      <td>Will Ferrell, Chris Kattan, Raquel Gardner, Vi...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Argentina:13, Australia:M, Brazil:14, Canada:P...</td>\n",
       "      <td>Two dim-witted brothers dream of owning their ...</td>\n",
       "      <td>The Roxbury Guys, Steve and Doug Butabi, want ...</td>\n",
       "      <td>woman-on-top, nightclub, car-accident, 1990s, ...</td>\n",
       "      <td>Comedy, Music, Romance</td>\n",
       "      <td>Score!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132512</td>\n",
       "      <td>At First Sight</td>\n",
       "      <td>Sight Unseen (United States), Premier regard (...</td>\n",
       "      <td>1999</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>12922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States:</td>\n",
       "      <td>Rob Cowan, Roger Paradiso, Irwin Winkler</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Irwin Winkler</td>\n",
       "      <td>Kerry Barden, Billy Hopkins, Suzanne Smith</td>\n",
       "      <td>Val Kilmer, Mira Sorvino, Kelly McGillis, Stev...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Argentina:13, Australia:M, Canada:PG::(Alberta...</td>\n",
       "      <td>A blind man has an operation to regain his sig...</td>\n",
       "      <td>First Sight is true to the title from start to...</td>\n",
       "      <td>visual-agnosia, brother-sister-relationship, r...</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>Only Love Can Bring You To Your Senses., Scien...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118661</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>Chapeau melon et bottes de cuir (France), Mit ...</td>\n",
       "      <td>1998</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>40784</td>\n",
       "      <td>FMCJ Award 1998, Golden Reel Award 1999, Razzi...</td>\n",
       "      <td>United States: $10,305,957, 16 Aug 1998</td>\n",
       "      <td>Susan Ekins, Jerry Weintraub</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>Sharon Mansfield, Anna Worley</td>\n",
       "      <td>...</td>\n",
       "      <td>Jeremiah S. Chechik</td>\n",
       "      <td>Susie Figgis</td>\n",
       "      <td>Ralph Fiennes, Uma Thurman, Sean Connery, Patr...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Argentina:13, Australia:PG, Brazil:10, Canada:...</td>\n",
       "      <td>Two British Agents team up to stop Sir August ...</td>\n",
       "      <td>British Ministry Agent John Steed, under direc...</td>\n",
       "      <td>good-versus-evil, heroine, evil-man, villain, ...</td>\n",
       "      <td>Action, Adventure, Sci-Fi, Thriller</td>\n",
       "      <td>Mrs. Peel, we're needed., Extraordinary crimes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215545</td>\n",
       "      <td>Bamboozled</td>\n",
       "      <td>The Very Black Show (France), It's Showtime (G...</td>\n",
       "      <td>2000</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>10373</td>\n",
       "      <td>Golden Berlin Bear 2001, Black Reel 2001, Imag...</td>\n",
       "      <td>United States:</td>\n",
       "      <td>Jon Kilik, Spike Lee, Kisha Imani Cameron</td>\n",
       "      <td>$10,000,000 (estimated)</td>\n",
       "      <td>Shari L. Carpenter, Carolyn De Sousa</td>\n",
       "      <td>...</td>\n",
       "      <td>Spike Lee</td>\n",
       "      <td>Aisha Coley</td>\n",
       "      <td>Damon Wayans, Savion Glover, Jada Pinkett Smit...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Australia:MA, Finland:K-15, France:Tous public...</td>\n",
       "      <td>A frustrated African-American TV writer propos...</td>\n",
       "      <td>Dark, biting satire of the television industry...</td>\n",
       "      <td>television-industry, african-american, referen...</td>\n",
       "      <td>Comedy, Drama, Music</td>\n",
       "      <td>Starring the great negroe actors</td>\n",
       "      <td>In a New York City residence, Pierre Delacroix...</td>\n",
       "      <td>\\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118715</td>\n",
       "      <td>The Big Lebowski</td>\n",
       "      <td>El gran Lebowski (Spain), O Grande Lebowski (P...</td>\n",
       "      <td>1998</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>724388</td>\n",
       "      <td>Honorable Mention 1998, ACCA 1998, Golden Berl...</td>\n",
       "      <td>United States: $5,533,844, 08 Mar 1998</td>\n",
       "      <td>Tim Bevan, John Cameron, Ethan Coen, Eric Fell...</td>\n",
       "      <td>$15,000,000 (estimated)</td>\n",
       "      <td>T. Kukovinski</td>\n",
       "      <td>...</td>\n",
       "      <td>Joel Coen, Ethan Coen</td>\n",
       "      <td>John S. Lyons</td>\n",
       "      <td>Jeff Bridges, John Goodman, Julianne Moore, St...</td>\n",
       "      <td>United States, United Kingdom</td>\n",
       "      <td>Argentina:16, Argentina:18::(cable rating), Au...</td>\n",
       "      <td>Jeff \"The Dude\" Lebowski, mistaken for a milli...</td>\n",
       "      <td>When \"the dude\" Lebowski is mistaken for a mil...</td>\n",
       "      <td>rug, nihilism, pornographer, bowling-alley, de...</td>\n",
       "      <td>Comedy, Crime, Sport</td>\n",
       "      <td>Hay quienes tratan de ganarse la vida sin move...</td>\n",
       "      <td>A tumbleweed rolls up a hillside just outside ...</td>\n",
       "      <td>\\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbid                   title  \\\n",
       "0  120770  A Night at the Roxbury   \n",
       "1  132512          At First Sight   \n",
       "2  118661            The Avengers   \n",
       "3  215545              Bamboozled   \n",
       "4  118715        The Big Lebowski   \n",
       "\n",
       "                                                akas  year  metascore  \\\n",
       "0  Une nuit au Roxbury (France), Movida en el Rox...  1998         26   \n",
       "1  Sight Unseen (United States), Premier regard (...  1999         40   \n",
       "2  Chapeau melon et bottes de cuir (France), Mit ...  1998         12   \n",
       "3  The Very Black Show (France), It's Showtime (G...  2000         54   \n",
       "4  El gran Lebowski (Spain), O Grande Lebowski (P...  1998         71   \n",
       "\n",
       "   imdb user rating  number of imdb user votes  \\\n",
       "0                 6                      56537   \n",
       "1                 6                      12922   \n",
       "2                 3                      40784   \n",
       "3                 6                      10373   \n",
       "4                 8                     724388   \n",
       "\n",
       "                                              awards  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  FMCJ Award 1998, Golden Reel Award 1999, Razzi...   \n",
       "3  Golden Berlin Bear 2001, Black Reel 2001, Imag...   \n",
       "4  Honorable Mention 1998, ACCA 1998, Golden Berl...   \n",
       "\n",
       "                           opening weekend  \\\n",
       "0                          United States:    \n",
       "1                          United States:    \n",
       "2  United States: $10,305,957, 16 Aug 1998   \n",
       "3                          United States:    \n",
       "4   United States: $5,533,844, 08 Mar 1998   \n",
       "\n",
       "                                           producers                   budget  \\\n",
       "0  Marie Cantin, Erin Fraser, Amy Heckerling, Ste...  $17,000,000 (estimated)   \n",
       "1           Rob Cowan, Roger Paradiso, Irwin Winkler  $60,000,000 (estimated)   \n",
       "2                       Susan Ekins, Jerry Weintraub  $60,000,000 (estimated)   \n",
       "3          Jon Kilik, Spike Lee, Kisha Imani Cameron  $10,000,000 (estimated)   \n",
       "4  Tim Bevan, John Cameron, Ethan Coen, Eric Fell...  $15,000,000 (estimated)   \n",
       "\n",
       "                      script department  ...              directors  \\\n",
       "0                                   NaN  ...       John Fortenberry   \n",
       "1                                   NaN  ...          Irwin Winkler   \n",
       "2         Sharon Mansfield, Anna Worley  ...    Jeremiah S. Chechik   \n",
       "3  Shari L. Carpenter, Carolyn De Sousa  ...              Spike Lee   \n",
       "4                         T. Kukovinski  ...  Joel Coen, Ethan Coen   \n",
       "\n",
       "                            casting directors  \\\n",
       "0                              Jeff Greenberg   \n",
       "1  Kerry Barden, Billy Hopkins, Suzanne Smith   \n",
       "2                                Susie Figgis   \n",
       "3                                 Aisha Coley   \n",
       "4                               John S. Lyons   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Will Ferrell, Chris Kattan, Raquel Gardner, Vi...   \n",
       "1  Val Kilmer, Mira Sorvino, Kelly McGillis, Stev...   \n",
       "2  Ralph Fiennes, Uma Thurman, Sean Connery, Patr...   \n",
       "3  Damon Wayans, Savion Glover, Jada Pinkett Smit...   \n",
       "4  Jeff Bridges, John Goodman, Julianne Moore, St...   \n",
       "\n",
       "                       countries  \\\n",
       "0                  United States   \n",
       "1                  United States   \n",
       "2                  United States   \n",
       "3                  United States   \n",
       "4  United States, United Kingdom   \n",
       "\n",
       "                                        age restrict  \\\n",
       "0  Argentina:13, Australia:M, Brazil:14, Canada:P...   \n",
       "1  Argentina:13, Australia:M, Canada:PG::(Alberta...   \n",
       "2  Argentina:13, Australia:PG, Brazil:10, Canada:...   \n",
       "3  Australia:MA, Finland:K-15, France:Tous public...   \n",
       "4  Argentina:16, Argentina:18::(cable rating), Au...   \n",
       "\n",
       "                                                plot  \\\n",
       "0  Two dim-witted brothers dream of owning their ...   \n",
       "1  A blind man has an operation to regain his sig...   \n",
       "2  Two British Agents team up to stop Sir August ...   \n",
       "3  A frustrated African-American TV writer propos...   \n",
       "4  Jeff \"The Dude\" Lebowski, mistaken for a milli...   \n",
       "\n",
       "                                        plot outline  \\\n",
       "0  The Roxbury Guys, Steve and Doug Butabi, want ...   \n",
       "1  First Sight is true to the title from start to...   \n",
       "2  British Ministry Agent John Steed, under direc...   \n",
       "3  Dark, biting satire of the television industry...   \n",
       "4  When \"the dude\" Lebowski is mistaken for a mil...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  woman-on-top, nightclub, car-accident, 1990s, ...   \n",
       "1  visual-agnosia, brother-sister-relationship, r...   \n",
       "2  good-versus-evil, heroine, evil-man, villain, ...   \n",
       "3  television-industry, african-american, referen...   \n",
       "4  rug, nihilism, pornographer, bowling-alley, de...   \n",
       "\n",
       "                                genres  \\\n",
       "0               Comedy, Music, Romance   \n",
       "1                       Drama, Romance   \n",
       "2  Action, Adventure, Sci-Fi, Thriller   \n",
       "3                 Comedy, Drama, Music   \n",
       "4                 Comedy, Crime, Sport   \n",
       "\n",
       "                                            taglines  \\\n",
       "0                                             Score!   \n",
       "1  Only Love Can Bring You To Your Senses., Scien...   \n",
       "2  Mrs. Peel, we're needed., Extraordinary crimes...   \n",
       "3                   Starring the great negroe actors   \n",
       "4  Hay quienes tratan de ganarse la vida sin move...   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  In a New York City residence, Pierre Delacroix...   \n",
       "4  A tumbleweed rolls up a hillside just outside ...   \n",
       "\n",
       "                                          screenplay  \n",
       "0  \\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...  \n",
       "1  AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...  \n",
       "2  \\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...  \n",
       "3  \\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...  \n",
       "4  \\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure 'imdbid' is of the correct type in both DataFrames before merging, if needed\n",
    "if screenplays_df['imdbid'].dtype != 'int':\n",
    "    screenplays_df['imdbid'] = screenplays_df['imdbid'].astype(int)\n",
    "\n",
    "# Merge with metadata on 'imdbid'\n",
    "df = meta_df.merge(screenplays_df, on='imdbid')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "671b878c-5525-4fef-b2f1-12cf6ea16508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>opening weekend</th>\n",
       "      <th>budget</th>\n",
       "      <th>age restrict</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120770</td>\n",
       "      <td>A Night at the Roxbury</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$17,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:M, Brazil:14, Canada:P...</td>\n",
       "      <td>Comedy, Music, Romance</td>\n",
       "      <td>\\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132512</td>\n",
       "      <td>At First Sight</td>\n",
       "      <td>1999</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:M, Canada:PG::(Alberta...</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118661</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States: $10,305,957, 16 Aug 1998</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:PG, Brazil:10, Canada:...</td>\n",
       "      <td>Action, Adventure, Sci-Fi, Thriller</td>\n",
       "      <td>\\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215545</td>\n",
       "      <td>Bamboozled</td>\n",
       "      <td>2000</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$10,000,000 (estimated)</td>\n",
       "      <td>Australia:MA, Finland:K-15, France:Tous public...</td>\n",
       "      <td>Comedy, Drama, Music</td>\n",
       "      <td>\\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118715</td>\n",
       "      <td>The Big Lebowski</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States: $5,533,844, 08 Mar 1998</td>\n",
       "      <td>$15,000,000 (estimated)</td>\n",
       "      <td>Argentina:16, Argentina:18::(cable rating), Au...</td>\n",
       "      <td>Comedy, Crime, Sport</td>\n",
       "      <td>\\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbid                   title  year  \\\n",
       "0  120770  A Night at the Roxbury  1998   \n",
       "1  132512          At First Sight  1999   \n",
       "2  118661            The Avengers  1998   \n",
       "3  215545              Bamboozled  2000   \n",
       "4  118715        The Big Lebowski  1998   \n",
       "\n",
       "                           opening weekend                   budget  \\\n",
       "0                          United States:   $17,000,000 (estimated)   \n",
       "1                          United States:   $60,000,000 (estimated)   \n",
       "2  United States: $10,305,957, 16 Aug 1998  $60,000,000 (estimated)   \n",
       "3                          United States:   $10,000,000 (estimated)   \n",
       "4   United States: $5,533,844, 08 Mar 1998  $15,000,000 (estimated)   \n",
       "\n",
       "                                        age restrict  \\\n",
       "0  Argentina:13, Australia:M, Brazil:14, Canada:P...   \n",
       "1  Argentina:13, Australia:M, Canada:PG::(Alberta...   \n",
       "2  Argentina:13, Australia:PG, Brazil:10, Canada:...   \n",
       "3  Australia:MA, Finland:K-15, France:Tous public...   \n",
       "4  Argentina:16, Argentina:18::(cable rating), Au...   \n",
       "\n",
       "                                genres  \\\n",
       "0               Comedy, Music, Romance   \n",
       "1                       Drama, Romance   \n",
       "2  Action, Adventure, Sci-Fi, Thriller   \n",
       "3                 Comedy, Drama, Music   \n",
       "4                 Comedy, Crime, Sport   \n",
       "\n",
       "                                          screenplay  \n",
       "0  \\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...  \n",
       "1  AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...  \n",
       "2  \\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...  \n",
       "3  \\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...  \n",
       "4  \\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lean version of the dataframe with only relevant columns for predicting age restrict classification\n",
    "df_lean = df[['imdbid', 'title', 'year', 'opening weekend', 'budget', 'age restrict', 'genres', 'screenplay']]\n",
    "df_lean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb1927d-1c81-4637-a3f0-c1ff23ae4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2853 entries, 0 to 2852\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   imdbid           2853 non-null   int64 \n",
      " 1   title            2853 non-null   object\n",
      " 2   year             2853 non-null   int64 \n",
      " 3   opening weekend  1736 non-null   object\n",
      " 4   budget           1623 non-null   object\n",
      " 5   age restrict     2524 non-null   object\n",
      " 6   genres           2841 non-null   object\n",
      " 7   screenplay       2853 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 178.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_lean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b8fff82-daab-4d1b-99fe-253d1bdc903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2853, 8), 329)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess missing values in 'age restrict' and print the shape in a single step\n",
    "missing_values = df_lean['age restrict'].isnull().sum()\n",
    "df_lean.shape, missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c62929-e946-445a-8adf-77fa2c915cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2524, 8), 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values in 'age restrict' and check the shape in a single step\n",
    "df_clean = df_lean.dropna(subset=['age restrict'])\n",
    "df_clean.shape, df_clean['age restrict'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6b71e2-1530-4294-b73e-df48ccedf39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           M\n",
       "1           M\n",
       "2          PG\n",
       "3        <NA>\n",
       "4          MA\n",
       "        ...  \n",
       "2848     <NA>\n",
       "2849       PG\n",
       "2850    MA15+\n",
       "2851       PG\n",
       "2852    MA15+\n",
       "Name: age restrict, Length: 2524, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the pattern once outside the function to avoid repeated compilation\n",
    "pattern = re.compile(r', Australia:(G|PG|M|MA|MA15\\+|R), ')\n",
    "\n",
    "def find_aus_classification(string):\n",
    "    match = pattern.search(string)  # Use the precompiled pattern\n",
    "    return match.group(1) if match else pd.NA\n",
    "\n",
    "aus_classifications = df_clean['age restrict'].apply(find_aus_classification)\n",
    "aus_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747ceec1-4abd-4d7a-8b09-e0638a9facbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_7736\\58119831.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['age restrict aus'] = aus_classifications\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>opening weekend</th>\n",
       "      <th>budget</th>\n",
       "      <th>age restrict</th>\n",
       "      <th>genres</th>\n",
       "      <th>screenplay</th>\n",
       "      <th>age restrict aus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120770</td>\n",
       "      <td>A Night at the Roxbury</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$17,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:M, Brazil:14, Canada:P...</td>\n",
       "      <td>Comedy, Music, Romance</td>\n",
       "      <td>\\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132512</td>\n",
       "      <td>At First Sight</td>\n",
       "      <td>1999</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:M, Canada:PG::(Alberta...</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118661</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States: $10,305,957, 16 Aug 1998</td>\n",
       "      <td>$60,000,000 (estimated)</td>\n",
       "      <td>Argentina:13, Australia:PG, Brazil:10, Canada:...</td>\n",
       "      <td>Action, Adventure, Sci-Fi, Thriller</td>\n",
       "      <td>\\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215545</td>\n",
       "      <td>Bamboozled</td>\n",
       "      <td>2000</td>\n",
       "      <td>United States:</td>\n",
       "      <td>$10,000,000 (estimated)</td>\n",
       "      <td>Australia:MA, Finland:K-15, France:Tous public...</td>\n",
       "      <td>Comedy, Drama, Music</td>\n",
       "      <td>\\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118715</td>\n",
       "      <td>The Big Lebowski</td>\n",
       "      <td>1998</td>\n",
       "      <td>United States: $5,533,844, 08 Mar 1998</td>\n",
       "      <td>$15,000,000 (estimated)</td>\n",
       "      <td>Argentina:16, Argentina:18::(cable rating), Au...</td>\n",
       "      <td>Comedy, Crime, Sport</td>\n",
       "      <td>\\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbid                   title  year  \\\n",
       "0  120770  A Night at the Roxbury  1998   \n",
       "1  132512          At First Sight  1999   \n",
       "2  118661            The Avengers  1998   \n",
       "3  215545              Bamboozled  2000   \n",
       "4  118715        The Big Lebowski  1998   \n",
       "\n",
       "                           opening weekend                   budget  \\\n",
       "0                          United States:   $17,000,000 (estimated)   \n",
       "1                          United States:   $60,000,000 (estimated)   \n",
       "2  United States: $10,305,957, 16 Aug 1998  $60,000,000 (estimated)   \n",
       "3                          United States:   $10,000,000 (estimated)   \n",
       "4   United States: $5,533,844, 08 Mar 1998  $15,000,000 (estimated)   \n",
       "\n",
       "                                        age restrict  \\\n",
       "0  Argentina:13, Australia:M, Brazil:14, Canada:P...   \n",
       "1  Argentina:13, Australia:M, Canada:PG::(Alberta...   \n",
       "2  Argentina:13, Australia:PG, Brazil:10, Canada:...   \n",
       "3  Australia:MA, Finland:K-15, France:Tous public...   \n",
       "4  Argentina:16, Argentina:18::(cable rating), Au...   \n",
       "\n",
       "                                genres  \\\n",
       "0               Comedy, Music, Romance   \n",
       "1                       Drama, Romance   \n",
       "2  Action, Adventure, Sci-Fi, Thriller   \n",
       "3                 Comedy, Drama, Music   \n",
       "4                 Comedy, Crime, Sport   \n",
       "\n",
       "                                          screenplay age restrict aus  \n",
       "0  \\n\\n\\t\\t\\t    A NIGHT AT THE ROXBURY \\n\\n\\n\\t\\...                M  \n",
       "1  AT FIRST SIGHT\\n\\nEXT. VALLEY - DUSK \\nGold li...                M  \n",
       "2  \\n\\n\\t\\t\\t\\t\\tTHE AVENGERS\\n\\n\\t\\t\\t\\tScreenpl...               PG  \n",
       "3  \\t\\t\\t\\tBamboozled\\n\\n\\t\\t\\t\\tby\\n\\n\\t\\t\\t\\tSp...             <NA>  \n",
       "4  \\n\\n\\t\\t\\tTHE BIG LEBOWSKI\\n\\nWe are floating ...               MA  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset with Australian classifications\n",
    "df_clean['age restrict aus'] = aus_classifications\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2625cf-e518-46e0-996a-b2c4c23c37e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1891, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values in 'age restrict aus' and output the shape\n",
    "df_aus = df_clean.dropna(subset=['age restrict aus'])\n",
    "df_aus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e9538",
   "metadata": {},
   "source": [
    "M (Mature) - Assigned a value of 0, this rating indicates content that is recommended for audiences aged 15 and above. It may contain moderate themes, violence, or coarse language. Viewer discretion is advised for younger audiences.\n",
    "\n",
    "PG (Parental Guidance) - With a value of 1, this rating suggests that some content may not be suitable for children without the guidance of a parent or guardian. Themes, language, and scenes are generally mild, but certain elements may require explanation or oversight.\n",
    "\n",
    "MA (Mature Audience) - Rated 2, this classification is for mature viewers aged 15 years and above, and may include strong themes, violence, or explicit language. Parental guidance is strongly recommended for younger viewers.\n",
    "\n",
    "G (General) - Rated 3, this classification means the content is suitable for all audiences. There are no themes, language, or visuals that would be inappropriate for children, making it family-friendly.\n",
    "\n",
    "R (Restricted) - Assigned a value of 4, this rating is for adults only (18+). It includes content that may feature explicit language, violence, sexual content, or other strong themes that are not suitable for younger audiences.\n",
    "\n",
    "MA15+ (Mature Audience 15+) - With the highest rating value of 5, this classification is specifically for people aged 15 and above. Content may include strong themes, violence, and other mature subject matter. Viewer discretion is required, and it is unsuitable for younger audiences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fde0d3",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dff561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with NaN in 'screenplay' or 'age restrict aus' columns...\n",
      "Cleaning 1891 screenplays...\n",
      "Vectorizing the cleaned screenplays...\n",
      "Vectorization complete. Feature matrix shape: (1891, 5000)\n",
      "Mapping age restriction labels to numerical values...\n",
      "Ensuring data consistency...\n",
      "Data cleaned. Total records after processing: 1891\n",
      "Splitting data into training and testing sets (80/20 split)...\n",
      "Training data: (1512, 5000), Test data: (379, 5000)\n",
      "Applying oversampling to balance the classes in the training data...\n",
      "After oversampling, training data shape: (4206, 5000)\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "Making predictions on the test set...\n",
      "Evaluating model performance...\n",
      "Accuracy: 0.3747\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           M       0.49      0.41      0.44       176\n",
      "          PG       0.39      0.39      0.39        67\n",
      "          MA       0.15      0.20      0.17        35\n",
      "           G       0.39      0.39      0.39        18\n",
      "           R       0.12      0.20      0.15        20\n",
      "       MA15+       0.38      0.41      0.40        63\n",
      "\n",
      "    accuracy                           0.37       379\n",
      "   macro avg       0.32      0.33      0.32       379\n",
      "weighted avg       0.40      0.37      0.38       379\n",
      "\n",
      "Predicting rating for a new screenplay: '\n",
      "\n",
      "\t\t\t    A NIGHT AT THE ROXBUR...'\n",
      "Predicted Rating: M\n",
      "Actual Rating: M\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Precompile regular expressions for efficiency\n",
    "newline_pattern = re.compile(r'\\n+')\n",
    "tab_pattern = re.compile(r'\\t+')\n",
    "space_pattern = re.compile(r' +')\n",
    "screenplay_formatting_pattern = re.compile(r'(FADE IN:|CUT TO:|EXT\\.|INT\\.|SUPERIMPOSE:)', re.IGNORECASE)\n",
    "meta_data_pattern = re.compile(r'(written by|&|June \\d{1,2}, \\d{4})', re.IGNORECASE)\n",
    "all_caps_pattern = re.compile(r'[A-Z]{2,}(?:\\s+[A-Z]{2,})*')\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_screenplay_text(text):\n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = newline_pattern.sub(' ', text)\n",
    "    # Replace tabs with a single space\n",
    "    text = tab_pattern.sub(' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = space_pattern.sub(' ', text)\n",
    "    # Remove screenplay formatting (e.g., FADE IN:, CUT TO:, etc.)\n",
    "    text = screenplay_formatting_pattern.sub('', text)\n",
    "    # Remove metadata like author names or dates\n",
    "    text = meta_data_pattern.sub('', text)\n",
    "    # Remove all caps, typically used for scene descriptions\n",
    "    text = all_caps_pattern.sub('', text)\n",
    "    # Remove special characters that are not part of standard sentences\n",
    "    text = re.sub(r'[^A-Za-z0-9\\'\\.\\?\\!,\\s]', '', text)\n",
    "    # Standardize single quotes\n",
    "    text = re.sub(r'[‘’]', \"'\", text)\n",
    "    # Standardize double quotes\n",
    "    text = re.sub(r'[“”]', '\"', text)\n",
    "    # Remove leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Assuming df_aus is a DataFrame with \"screenplay\" and \"age restrict aus\" columns\n",
    "print(\"Dropping rows with NaN in 'screenplay' or 'age restrict aus' columns...\")\n",
    "df_aus = df_aus.dropna(subset=['screenplay', 'age restrict aus'])  # Drop rows with NaNs\n",
    "\n",
    "print(f\"Cleaning {len(df_aus)} screenplays...\")\n",
    "df_aus['cleaned_screenplay'] = df_aus['screenplay'].apply(clean_screenplay_text)\n",
    "\n",
    "# Preprocessing: Vectorize the screenplays\n",
    "print(\"Vectorizing the cleaned screenplays...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df_aus['cleaned_screenplay'])\n",
    "print(f\"Vectorization complete. Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# Map the ratings to numerical values\n",
    "rating_mapping = {'M': 0, 'PG': 1, 'MA': 2, 'G': 3, 'R': 4, 'MA15+': 5}\n",
    "print(f\"Mapping age restriction labels to numerical values...\")\n",
    "df_aus['mapped_rating'] = df_aus['age restrict aus'].map(rating_mapping)\n",
    "\n",
    "# Drop any remaining NaN values in 'mapped_rating'\n",
    "print(\"Ensuring data consistency...\")\n",
    "df_aus = df_aus.dropna(subset=['mapped_rating'])\n",
    "\n",
    "# Ensure X is aligned with df_aus by slicing X with the same length as df_aus\n",
    "X = X[:len(df_aus)]\n",
    "y = df_aus['mapped_rating']\n",
    "print(f\"Data cleaned. Total records after processing: {len(df_aus)}\")\n",
    "\n",
    "# Split the dataset before oversampling\n",
    "print(\"Splitting data into training and testing sets (80/20 split)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training data: {X_train.shape}, Test data: {X_test.shape}\")\n",
    "\n",
    "# Oversample the training data\n",
    "print(\"Applying oversampling to balance the classes in the training data...\")\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "print(f\"After oversampling, training data shape: {X_train.shape}\")\n",
    "\n",
    "# Train the classifier\n",
    "print(\"Training Logistic Regression model...\")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Predict on the test set\n",
    "print(\"Making predictions on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating model performance...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred, target_names=list(rating_mapping.keys()))\n",
    ")\n",
    "\n",
    "# Function to predict the rating of new screenplays\n",
    "def predict_movie_rating(screenplay):\n",
    "    print(f\"Predicting rating for a new screenplay: '{screenplay[:30]}...'\")\n",
    "    screenplay_cleaned = clean_screenplay_text(screenplay)  # Clean new screenplay\n",
    "    screenplay_vector = tfidf_vectorizer.transform([screenplay_cleaned])\n",
    "    rating_index = model.predict(screenplay_vector)[0]\n",
    "    # Retrieve the rating label from the mapping\n",
    "    return {v: k for k, v in rating_mapping.items()}[rating_index]\n",
    "\n",
    "# Example usage: Provide a new screenplay text (instead of passing a DataFrame column)\n",
    "new_screenplay_text, actual_rating = df_aus[[\"screenplay\", \"age restrict aus\"]].iloc[0]\n",
    "predicted_rating = predict_movie_rating(new_screenplay_text)\n",
    "print(f\"Predicted Rating: {predicted_rating}\")\n",
    "print(f\"Actual Rating: {actual_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65f11d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c57922c24e4be8a1a9bd232ffe0b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\syahr\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13288849d8624632a8e7347877301869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c239662a1cc34f2e8952bd4ee1e9009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b34572dd384b92b2c0c68536db938a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ecc2d3bb734ebf97c9b742d4a6fbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf004f18bbf423a8879a9eec08195de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test}))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Tokenize the datasets\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenize_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenize_function(e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]), batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:3035\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3031\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3032\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3033\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3034\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3035\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3036\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3037\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:3438\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3434\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3435\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3436\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3438\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3442\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3447\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:3300\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3299\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3300\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3302\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3303\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3304\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[58], line 54\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     51\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test}))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Tokenize the datasets\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[43mtokenize_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m e: tokenize_function(e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]), batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[58], line 47\u001b[0m, in \u001b[0;36mtokenize_function\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(texts):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3016\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   3015\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 3016\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3104\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3099\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3100\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3101\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3102\u001b[0m         )\n\u001b[0;32m   3103\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 3104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3106\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   3127\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3128\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3306\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3296\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3297\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3298\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3299\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3303\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3304\u001b[0m )\n\u001b[1;32m-> 3306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils.py:885\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 885\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    887\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils.py:852\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 852\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils.py:695\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:161\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[1;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[0;32m    159\u001b[0m split_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_basic_tokenize:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# If the token is part of the never_split set\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_tokenizer\u001b[38;5;241m.\u001b[39mnever_split:\n\u001b[0;32m    166\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:358\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[1;34m(self, text, never_split)\u001b[0m\n\u001b[0;32m    356\u001b[0m     token \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_strip_accents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents:\n\u001b[0;32m    360\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_strip_accents(token)\n",
      "File \u001b[1;32mc:\\Users\\syahr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:374\u001b[0m, in \u001b[0;36mBasicTokenizer._run_strip_accents\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(char)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(output)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compile regex patterns once to improve efficiency\n",
    "newline_pattern = re.compile(r'\\n+')\n",
    "tab_pattern = re.compile(r'\\t+')\n",
    "space_pattern = re.compile(r'\\s+')\n",
    "screenplay_formatting_pattern = re.compile(r'(INT\\.|EXT\\.)')\n",
    "meta_data_pattern = re.compile(r'\\[.*?\\]')\n",
    "all_caps_pattern = re.compile(r'\\b[A-Z]{2,}\\b')\n",
    "\n",
    "# Clean screenplay text\n",
    "def clean_screenplay_text(text):\n",
    "    text = newline_pattern.sub(' ', text)\n",
    "    text = tab_pattern.sub(' ', text)\n",
    "    text = space_pattern.sub(' ', text)\n",
    "    text = screenplay_formatting_pattern.sub('', text)\n",
    "    text = meta_data_pattern.sub('', text)\n",
    "    text = all_caps_pattern.sub('', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\'\\.\\?\\!,\\s]', '', text)\n",
    "    text = re.sub(r'[‘’]', \"'\", text)\n",
    "    text = re.sub(r'[“”]', '\"', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess screenplays and ratings\n",
    "print(\"Cleaning screenplay texts...\")\n",
    "df_aus['cleaned_screenplay'] = df_aus['screenplay'].apply(clean_screenplay_text)\n",
    "print(f\"Sample cleaned screenplay: {df_aus['cleaned_screenplay'].iloc[0]}\")\n",
    "\n",
    "# Map ratings to numerical values\n",
    "print(\"Mapping age restrictions to numerical values...\")\n",
    "rating_mapping = {'M': 0, 'PG': 1, 'MA': 2, 'G': 3, 'R': 4, 'MA15+': 5}\n",
    "df_aus['mapped_rating'] = df_aus['age restrict aus'].map(rating_mapping)\n",
    "print(f\"Sample mapped rating: {df_aus['mapped_rating'].iloc[0]}\")\n",
    "\n",
    "# Drop rows with NaNs and split data\n",
    "print(\"Dropping rows with missing values...\")\n",
    "df_aus.dropna(subset=['cleaned_screenplay', 'mapped_rating'], inplace=True)\n",
    "print(f\"Data after dropping NaNs: {len(df_aus)} rows\")\n",
    "\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_aus['cleaned_screenplay'], df_aus['mapped_rating'], test_size=0.2, random_state=42, stratify=df_aus['mapped_rating']\n",
    ")\n",
    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "\n",
    "# Tokenizer and model initialization\n",
    "print(\"Loading BERT tokenizer and model...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(rating_mapping))\n",
    "\n",
    "# Tokenize data\n",
    "print(\"Tokenizing data...\")\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Convert data to Hugging Face Dataset format\n",
    "print(\"Converting data to Dataset format...\")\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame({'text': X_train, 'label': y_train}))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame({'text': X_test, 'label': y_test}))\n",
    "\n",
    "print(\"Tokenizing training and test datasets...\")\n",
    "train_dataset = train_dataset.map(lambda e: tokenize_function(e['text']), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenize_function(e['text']), batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# Training arguments\n",
    "print(\"Setting up training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "print(\"Training arguments set.\")\n",
    "\n",
    "# Define Trainer\n",
    "print(\"Initializing Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': accuracy_score(p.label_ids, p.predictions.argmax(-1))},\n",
    ")\n",
    "print(\"Trainer initialized.\")\n",
    "\n",
    "# Train and evaluate the model\n",
    "print(\"Training the model...\")\n",
    "trainer.train()\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"Evaluation complete. Accuracy: {metrics['eval_accuracy']:.4f}\")\n",
    "\n",
    "# Function to predict rating\n",
    "def predict_movie_rating(screenplay):\n",
    "    screenplay_cleaned = clean_screenplay_text(screenplay)\n",
    "    inputs = tokenizer(screenplay_cleaned, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    predicted_class_id = outputs.logits.argmax().item()\n",
    "    return {v: k for k, v in rating_mapping.items()}[predicted_class_id]\n",
    "\n",
    "# Example usage\n",
    "print(\"Predicting rating for a new screenplay...\")\n",
    "new_screenplay_text, actual_rating = df_aus[[\"screenplay\", \"age restrict aus\"]].iloc[0]\n",
    "predicted_rating = predict_movie_rating(new_screenplay_text)\n",
    "print(f\"Predicted Rating: {predicted_rating}\")\n",
    "print(f\"Actual Rating: {actual_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9238e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
